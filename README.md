# LLM Uncertainty Analysis

An√°lisis cuantitativo de incertidumbre predictiva en modelos de lenguaje autoregresivos utilizando teor√≠a de la informaci√≥n. Este proyecto en instancia intermedia se centra en c√≥mo el **In-Context Learning (ICL)** afecta la entrop√≠a predictiva en diferentes categor√≠as de tareas.

**Curso:** EL7024-1 Teor√≠a de la Informaci√≥n (2025-2)
**Universidad:** Universidad de Chile
**Autores:** Benito Fuentes, Sebastian Vergara

---

## Descripci√≥n del Proyecto

Este repositorio contiene una implementaci√≥n modular para medir y analizar la **incertidumbre predictiva** en modelos de lenguaje (GPT-2 family) usando **entrop√≠a de Shannon** como m√©trica principal. El proyecto eval√∫a c√≥mo el aprendizaje en contexto (ICL) reduce la incertidumbre del modelo en tres categor√≠as de tareas:

1. **Conocimiento Factual** (LAMA TREx)
2. **Razonamiento L√≥gico** (Stanford SNLI)
3. **Generaci√≥n Creativa** (Project Gutenberg Poetry)

### Hallazgos Principales

- **Razonamiento l√≥gico (SNLI)** muestra la mayor reducci√≥n de entrop√≠a: +4.75 bits (71% reducci√≥n en DistilGPT-2)
- **Conocimiento factual (LAMA)** exhibe **entrop√≠a negativa** en modelos peque√±os: -3.23 bits en DistilGPT-2 (ICL contraproducente)
- **Generaci√≥n creativa (Gutenberg)** permanece neutral: ŒîH ‚âà 0 bits
- **Escalamiento dependiente de tarea**: SNLI favorece modelos peque√±os (œÅ=-1.0), LAMA favorece modelos grandes (œÅ=+1.0)

---

## Estructura del Repositorio

### üìÇ Scripts Principales (Ra√≠z)

| Archivo | Descripci√≥n |
|---------|-------------|
| **`run_multi_model_icl_analysis.py`** | Script principal del experimento. Ejecuta an√°lisis multi-modelo ICL en 3 modelos GPT-2 con 1,800 prompts de benchmarks reales. Genera resultados, figuras y an√°lisis estad√≠stico completo. |
| **`explore_datasets.py`** | Herramienta de exploraci√≥n de datasets. Muestra estad√≠sticas detalladas de LAMA TREx (1,000 prompts factuales), Stanford SNLI (300 pares l√≥gicos) y Project Gutenberg (500 l√≠neas de poes√≠a). |
| **`load_real_datasets.py`** | Funciones auxiliares para cargar y procesar los tres datasets reales utilizados en el proyecto. Provee API unificada para acceso a datos. |

### üì¶ Paquete `llm_uncertainty_analysis/`

Paquete Python modular que implementa todo el pipeline de an√°lisis de incertidumbre:

```
llm_uncertainty_analysis/
‚îú‚îÄ‚îÄ config/              # Configuraci√≥n global y de visualizaci√≥n
‚îú‚îÄ‚îÄ data/                # Loaders para LAMA, SNLI, Gutenberg
‚îú‚îÄ‚îÄ metrics/             # Entrop√≠a de Shannon, Surprisal, Perplexity
‚îú‚îÄ‚îÄ analysis/            # Pipeline completo de an√°lisis de incertidumbre
‚îú‚îÄ‚îÄ statistics/          # ANOVA, Spearman, Kendall's W, Cohen's d
‚îú‚îÄ‚îÄ icl/                 # Generaci√≥n de prompts ICL y medici√≥n de entrop√≠a
‚îú‚îÄ‚îÄ visualization/       # Generaci√≥n de gr√°ficos estad√≠sticos
‚îú‚îÄ‚îÄ experiments/         # Experimento multi-modelo ICL (script principal)
‚îú‚îÄ‚îÄ models/              # Modelos de datos y configuraciones
‚îî‚îÄ‚îÄ utils/               # Utilidades y reproducibilidad
```

**Documentaci√≥n del paquete:** Ver `llm_uncertainty_analysis/README.md`

### üóÑÔ∏è Carpeta `data/`

Contiene los tres datasets de benchmarks reales utilizados en el proyecto:

- **`lama_data/`**: LAMA TREx (Language Model Analysis)
  - 1,000 prompts de conocimiento factual
  - 4 relaciones Wikidata: P19 (nacimiento), P37 (idioma), P106 (ocupaci√≥n), P36 (capital)

- **`gutenberg-poetry-v001.ndjson.gz`**: Project Gutenberg Poetry
  - 3.08M+ l√≠neas de poes√≠a de 1,191 libros cl√°sicos
  - Muestreo estratificado: 500 l√≠neas de 50 obras (1800-1922)

- **`consolidated_datasets.csv/json`**: Datasets consolidados
  - Incluye 300 prompts de Stanford SNLI
  - Pares premise-hypothesis balanceados (entailment/neutral/contradiction)

### üìà Carpeta `outputs/`

Resultados de experimentos en formato JSON:

```
outputs/
‚îî‚îÄ‚îÄ multi_model_icl/
    ‚îú‚îÄ‚îÄ results.json                  # Resultados completos del experimento
    ‚îú‚îÄ‚îÄ statistical_analysis.json     # ANOVA, correlaciones, post-hoc tests
    ‚îî‚îÄ‚îÄ hypothesis_validation.json    # Validaci√≥n de H1 (scaling) y H2 (consistency)
```

### üìä Carpeta `out/`

Resultados intermedios y m√©tricas token-level en formato CSV:

- `etapa2_tokens_metrics_all_models.csv`: M√©tricas por token para todos los modelos
- `etapa2_agregados_por_modelo.csv`: Agregados estad√≠sticos por modelo
- `etapa2_agregados_por_texto.csv`: Agregados por texto/prompt
- `etapa2_benchmark.json`: Benchmarks de rendimiento

### üìâ Carpeta `fig/`

Visualizaciones generadas (formato PNG):

- `icl_comprehensive_analysis.png`: An√°lisis comprensivo de ICL
- `entropy_by_category_*.png`: Comparaciones de entrop√≠a por categor√≠a
- `icl_mutual_information_heatmap.png`: Heatmap de informaci√≥n mutua
- `etapa2_*.png`: Visualizaciones de an√°lisis intermedios

### üóÉÔ∏è Carpeta `old_code/`

C√≥digo legacy del proyecto (notebooks de hitos, implementaciones anteriores). Ver `old_code/README.md` para detalles.

---

## Instalaci√≥n

### Requisitos

- Python 3.8+
- CUDA-capable GPU (opcional, recomendado para experimentos grandes)

### Instalaci√≥n de Dependencias

```bash
# Clonar el repositorio
git clone <repository-url>
cd Proyecto

# Crear entorno virtual
python -m venv .venv
source .venv/bin/activate  # En Windows: .venv\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt
```

#### Dependencias Principales

- **transformers** (4.44.2): Modelos Hugging Face (GPT-2)
- **torch** (>=2.3.0): PyTorch para inferencia
- **numpy**, **pandas**: Procesamiento de datos
- **matplotlib**, **seaborn**: Visualizaci√≥n
- **scipy**, **statsmodels**: An√°lisis estad√≠stico
- **datasets**: Carga de SNLI desde Hugging Face

Para soporte GPU, instalar PyTorch con CUDA:
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

---

## Uso

### Ejecutar Experimento Principal

```bash
# Experimento completo (1,800 prompts, ~17 segundos en GPU)
python run_multi_model_icl_analysis.py

# Experimento r√°pido (subset de datos para testing)
python run_multi_model_icl_analysis.py --quick
```

**Salida:**
- Resultados JSON en `outputs/multi_model_icl/`
- Figuras PNG en `fig/`
- An√°lisis estad√≠stico completo (ANOVA, correlaciones)

### Explorar Datasets

```bash
# Mostrar estad√≠sticas de LAMA, SNLI, Gutenberg
python explore_datasets.py
```

**Salida:**
```
LAMA TREx: 1,000 prompts factuales (4 relaciones Wikidata)
Stanford SNLI: 300 pares l√≥gicos (balanceados)
Project Gutenberg: 500 l√≠neas de poes√≠a (50 libros)
```

### Usar el Paquete en Python

```python
from llm_uncertainty_analysis.experiments import run_multi_model_icl_experiment

# Ejecutar experimento personalizado
results = run_multi_model_icl_experiment(
    model_ids=['distilgpt2', 'gpt2', 'gpt2-medium'],
    n_examples_range=[0, 1, 2, 3, 5],  # k-shot configurations
    n_queries_per_config=10,
    device='cuda'
)

# Acceder a resultados
print(results['results_by_model']['distilgpt2']['categories']['factual'])
```

---

## Datasets

### LAMA TREx (Factual Knowledge)

**Fuente:** Petroni et al. 2019 - "Language Models as Knowledge Bases?"

- **Tama√±o:** 1,000 prompts
- **Relaciones Wikidata:**
  - P19: Lugar de nacimiento (250 prompts)
  - P37: Idioma oficial (250 prompts)
  - P106: Ocupaci√≥n (250 prompts)
  - P36: Capital (250 prompts)
- **Formato:** `"The official language of France is"` ‚Üí `"French"`

### Stanford SNLI (Logical Reasoning)

**Fuente:** Bowman et al. 2015 - "A large annotated corpus for learning natural language inference"

- **Tama√±o:** 300 pares premise-hypothesis
- **Labels balanceados:**
  - Entailment: 100 pares
  - Neutral: 100 pares
  - Contradiction: 100 pares
- **Formato:** `"Premise: ... Hypothesis: ... Relation:"` ‚Üí `"entailment"`

### Project Gutenberg (Creative Generation)

**Fuente:** Project Gutenberg 2024

- **Tama√±o:** 500 l√≠neas de poes√≠a
- **Obras:** 50 libros cl√°sicos (1800-1922)
- **Muestreo:** Estratificado (10 l√≠neas por libro)
- **Formato:** Predicci√≥n de siguiente l√≠nea po√©tica

---

## Modelos Analizados

| Modelo | Par√°metros | VRAM | Descripci√≥n |
|--------|------------|------|-------------|
| **DistilGPT-2** | 82M | 0.3 GB | Versi√≥n destilada de GPT-2, compresi√≥n de conocimiento |
| **GPT-2** | 124M | 0.5 GB | GPT-2 Small original, modelo baseline |
| **GPT-2 Medium** | 355M | 1.5 GB | GPT-2 Medium, mayor capacidad |

**Rango:** 4.3√ó en n√∫mero de par√°metros (82M - 355M)

---

## M√©tricas

### Entrop√≠a de Shannon (H)

```python
H = -Œ£ p(x) * log‚ÇÇ(p(x))
```

Mide la **incertidumbre** del modelo sobre la distribuci√≥n completa de probabilidad del siguiente token.

- **Unidad:** bits
- **Interpretaci√≥n:** Bits de informaci√≥n necesarios para codificar la distribuci√≥n
- **Rango:** 0 (certeza total) a log‚ÇÇ(|V|) (incertidumbre m√°xima)

### Reducci√≥n de Entrop√≠a (ŒîH)

```python
ŒîH = H(0-shot) - H(k-shot)
```

Mide la **efectividad del In-Context Learning** como reducci√≥n de incertidumbre.

- **ŒîH > 0:** ICL reduce incertidumbre (efectivo)
- **ŒîH = 0:** ICL no tiene efecto
- **ŒîH < 0:** ICL aumenta incertidumbre (contraproducente)

### M√©tricas Implementadas (No Usadas en Experimento ICL)

- **Surprisal:** `S = -log‚ÇÇ(p(y_true))` - Sorpresa ante token espec√≠fico
- **Perplexity:** `PPL = 2^S` - "N√∫mero efectivo de opciones equiprobables"

---

## Experimento

### Dise√±o Experimental

**Configuraciones k-shot:** [0, 1, 2, 3, 5]

Para cada combinaci√≥n de:
- **Modelo:** DistilGPT-2, GPT-2, GPT-2 Medium
- **Categor√≠a:** Factual (LAMA), Logical (SNLI), Creative (Gutenberg)
- **k-shot:** 0, 1, 2, 3, 5 ejemplos

Se mide:
1. Entrop√≠a predictiva H del primer token de respuesta
2. Reducci√≥n de entrop√≠a ŒîH respecto a baseline (0-shot)
3. An√°lisis estad√≠stico: ANOVA, Spearman, Kendall's W

### Hip√≥tesis Evaluadas

**H1 (Scaling):** "Modelos m√°s grandes muestran mayor efectividad ICL"
- **Resultado:** ‚ùå NO SOPORTADA
- **Evidencia:** Escalamiento es dependiente de tarea
  - SNLI: œÅ = -1.0 (modelos peque√±os mejor)
  - LAMA: œÅ = +1.0 (modelos grandes mejor)

**H2 (Consistency):** "El ranking de categor√≠as es consistente entre modelos"
- **Resultado:** ‚úÖ SOPORTADA
- **Evidencia:** Kendall's W = 1.000, p = 0.0498
- **Ranking:** logical > creative > factual (en todos los modelos)

---

## Resultados

### Reducci√≥n de Entrop√≠a por Categor√≠a (5-shot)

| Modelo | Factual (LAMA) | Logical (SNLI) | Creative (Gutenberg) |
|--------|----------------|----------------|----------------------|
| **DistilGPT-2** | -3.23 bits (-46%) | **+4.75 bits (+71%)** | -0.13 bits (-2%) |
| **GPT-2** | -1.65 bits (-23%) | **+4.25 bits (+51%)** | -0.21 bits (-3%) |
| **GPT-2 Medium** | -0.54 bits (-7%) | **+1.86 bits (+23%)** | +0.20 bits (+2%) |

**Significancia:** \*\*\* p < 0.001, \*\* p < 0.01, ns = not significant

### Interpretaci√≥n

1. **SNLI (Logical) es la categor√≠a m√°s efectiva para ICL**
   - Formato estructurado premise-hypothesis permite aprendizaje r√°pido
   - Incluso modelos peque√±os (82M par√°metros) logran 71% de reducci√≥n

2. **LAMA (Factual) muestra ŒîH negativo en modelos peque√±os**
   - Ejemplos multi-relaci√≥n (P19/P37/P106/P36 mezclados) confunden modelos con capacidad limitada
   - Solo modelos grandes (355M+) manejan la diversidad

3. **Gutenberg (Creative) permanece de alta entrop√≠a**
   - M√∫ltiples continuaciones po√©ticas igualmente v√°lidas
   - ICL no puede reducir incertidumbre inherente

4. **Escalamiento NO es universal**
   - SNLI: Modelos peque√±os superan a grandes (maleabilidad)
   - LAMA: Modelos grandes superan a peque√±os (capacidad)

---

## An√°lisis Estad√≠stico

### ANOVA de Dos V√≠as

**Efecto de Categor√≠a:** F = 16.15, p = 0.0038 (**significativo**)
- Las categor√≠as difieren significativamente en efectividad ICL

**Efecto de Modelo:** F = 0.01, p = 0.9894 (no significativo)
- No hay efecto global del tama√±o de modelo (es dependiente de categor√≠a)

### Correlaciones de Spearman

**Por Categor√≠a:**
- Factual (LAMA): œÅ = +1.0 (escalamiento positivo perfecto)
- Logical (SNLI): œÅ = -1.0 (escalamiento inverso perfecto)
- Creative (Gutenberg): œÅ = +0.5 (no significativo)

### Consistencia de Ranking (Kendall's W)

**W = 1.000, p = 0.0498**
- Acuerdo perfecto entre modelos en el ranking de categor√≠as
- Todos los modelos coinciden: SNLI > Gutenberg > LAMA

---

## Visualizaciones

Las figuras generadas se encuentran en `fig/`:

- **ICL Comprehensive Analysis:** Comparaci√≥n de entrop√≠a 0-shot vs 5-shot por categor√≠a
- **Entropy by Category:** Distribuciones de entrop√≠a con intervalos de confianza
- **Mutual Information Heatmap:** Informaci√≥n mutua entre ejemplos ICL y predicci√≥n
- **Scaling Analysis:** Correlaciones Spearman entre tama√±o de modelo y ŒîH

---

## Documentaci√≥n Adicional

- **`llm_uncertainty_analysis/README.md`**: Documentaci√≥n del paquete modular
- **`llm_uncertainty_analysis/QUICKSTART.md`**: Gu√≠a r√°pida de uso
- **`llm_uncertainty_analysis/STRUCTURE.md`**: Estructura detallada del c√≥digo
- **`llm_uncertainty_analysis/MIGRATION_GUIDE.md`**: Gu√≠a de migraci√≥n de c√≥digo legacy
- **`old_code/README.md`**: Documentaci√≥n del c√≥digo antiguo

---

## Referencias

### Datasets

- **LAMA TREx:** Petroni, F., et al. (2019). "Language models as knowledge bases?" *arXiv:1909.01066*.
- **Stanford SNLI:** Bowman, S. R., et al. (2015). "A large annotated corpus for learning natural language inference." *EMNLP 2015*.
- **Project Gutenberg:** [https://www.gutenberg.org/](https://www.gutenberg.org/)

### M√©tricas

- **Entrop√≠a & Surprisal:** Levy, R. (2008). "Expectation-based syntactic comprehension." *Cognition*, 106(3), 1126-1177.
- **Perplexity:** Goodkind, A., & Bicknell, K. (2018). "Predictive power of word surprisal for reading times is a linear function of language model quality." *CMCL 2018*.

---

## Licencia

Este proyecto fue desarrollado como parte del curso EL7024-1 Teor√≠a de la Informaci√≥n, Universidad de Chile (2025-2).

---

## Autores

**Benito Fuentes**
- Dise√±o experimental, implementaci√≥n de medici√≥n de entrop√≠a, an√°lisis estad√≠stico completo

**Sebastian Vergara**
- Pipeline multi-modelo, generaci√≥n de visualizaciones, validaci√≥n de hip√≥tesis

**Curso:** EL7024-1 2025-2
**Profesor:** Jorge Silva
**Gu√≠a:** Sim√≥n Vidal
